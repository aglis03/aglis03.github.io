---
title: "Final Project"
author: "Annika G. Lee & Jeffrey Zhao"
date: "December 15, 2023"
output: html_document
---

## Define Business Problem

Our business problem is to develop a predictive model that will help us accurately estimate and predict health insurance charges for individuals based on factors such as age, BMI, gender, number of children, smoking status, and region.

## Three High Quality Questions

1.  Are the home addresses of these patients also being included and used as a factor to determine predictions of charges in the datatset?
2.  What strategies can we develop to offer customer insurance that is best tailored to their needs based on their unique characteristics and environment?
3.  Will we be taking different kinds of health insurance plans into consideration when making predictions on charges? Income value, career, etc, can a play a big role to which coverage is granted to patients and their families.

## Translate Business Problem into an Analytics Problem

We can attempt to develop a regression based predictive model. The objective would be to build and train a model that accurately predicts health insurance charges. One approach is to utilize a dataset that contains these factors. Our main goal would be to minimize the predictive error and find predictions using such interpretations of error from a model.

## How CRISP-DM would apply to the process of providing a Solution?

CRISP-DM is used as a framework for data mining projects and has 6 steps. The first step is business understanding. We have to first identify what our objectives are and what constitutes our model as being successful. The next step is data understanding. We have to explore the dataset and see if there are any relationships between factors. The third step is data preparation. In this step we check for missing variables, and convert variables into factors. The fourth step is about modeling. In this step we split the data set into training and testing sets. Next we train the model. The fifth step is about evaluation. We have to evaluate how our model performed by looking at its accuracy and error. The final step is deployment. Once we are satisfied with our model, we use the model on new, unseen data.

## Prepare Data

```{r}
knitr::opts_chunk$set(echo = TRUE)
#| message: false
rm(list = ls())
library(tidyverse)
library(glmnet)
library(lubridate)
library(caret)
library(dummy)
library(gamlr)
library(rmarkdown)
library(GGally)
library(rpart)
library(rpart.plot)
library(corrplot)
```

## Read in Data

```{r}
insurance = read_csv("insurance.csv")
```

```{r}
glimpse(insurance)
```

## Check For Missing Variables

We can see that there are no missing variables within our data. This is a good sign for we do not have to replace any NA's within this dataset.

```{r}
sapply(insurance, function(x) mean(is.na(x)))
```

## Turn Variables into Factors

```{r}
insurance_fct = insurance %>%
  select(-age, -bmi, -charges) %>%
  mutate_all(.funs = factor)

insurance_num = insurance %>%
  select(age, bmi, charges)

insurance = bind_cols(insurance_num, insurance_fct)
```

## Summary

We can see that the \*\*minimum&& `age` within this dataset is 18. This makes sense for minors cannot purchase health insurance on their own. We can also see that the **median** `age` is 39 years old. One thing we notice is that the **mean** and **median** for `bmi` are both around 30, which goes into the obesity category. This could be a big factor in health insurance costs. One of the most important parts of the data are `charges`. We see that the **minimum** amount of `charges` for health insurance is \$1,122, and the **median** amout of `charges` for health insurance is \$9,382. The max amount of charges for health insurance is \$63,770. This is a big **discrepancy** that may come into play.

```{r}
summary(insurance)
```

## Correlation

We can see that our numeric values do not have strong correlations with one another, indicating that strong relationships are not present within our dataset. This is a good result to have for we will not have to exclude any features from our dataset.

```{r}
insurance %>%
  keep(is.numeric) %>%
  cor() %>%
  corrplot::corrplot(., method = "number", type = "lower", number.cex = 0.6, tl.cex = 0.7)
```

## Histogram

When looking at our Histogram for **Distribution of Charges**, we seem to have a right-skewed distribution within our model. This helps us visually see that a large amount of patients in this dataset have amount of `charges` below the **median** of the feature. We can easily see that many patients have lower amounts than higher amounts when it comes to `charges` for their health insurance.

```{r}
insurance %>%
  ggplot(aes(charges)) +
  geom_histogram(color = "black", bg = "skyblue") +
  labs(title = "Distribution of Charges",
       x = "Charges",
       y = "Count of patients") +
  theme_classic()
```

## Convert Variables into Dummy Variables

```{r}
insurance_dum = dummy(insurance, int = TRUE)
insurance_num = insurance %>%
  keep(is.numeric)
insurance = bind_cols(insurance_num, insurance_dum)
rm(insurance_dum, insurance_num)
```

## Partition Data

```{r}
#Partition Data
set.seed(123)
idx = createDataPartition(insurance$charges, p = 0.7, list = FALSE)
train = insurance[idx, ]
test = insurance[-idx, ]
rm(idx)
```

## Decision Tree

```{r}
train_model = train(charges ~ .,
                   data = train,
                   method = "rpart",
                   trControl = trainControl(method = "cv", number = 10),
                   tuneGrid = expand.grid(cp = seq(0.0, 0.01, 0.0001)),
                   control = rpart.control(minbucket = 1)
                   )
plot(train_model)
```

```{r}
library(rpart.plot)
rpart.plot(train_model$finalModel)
```

## Feature Importance

When looking at our data, we can see that the most important features are: `smoker_no` being the most important, `bmi`, and `age`. All other features seem to not have much of an importance within our dataset.

```{r}
library(iml)
library(patchwork)

tree_predictor = iml::Predictor$new(train_model,
                                    data = test,
                                    y = test$charges)

tree_imp = iml::FeatureImp$new(tree_predictor, loss = "rmse", compare = "ratio")
plot(tree_imp)
```

```{r}
tree_imp$results %>%
  filter(importance > 1)
```

## Train New Model

We will develop a new model using those three features we found to have the most important features. This will allow us to focus our new trained model on key factors that significantly affect health insurance charges. By focusing on only the most impactful variables, we can improve the predictive performance and possibly decrease the amount of error that may have been present earlier in our model.

```{r}
train_new = dplyr::select(train, smoker_no, bmi, age, charges)

new_tree = caret::train(charges ~ .,
                        data = train_new,
                        method = "rpart",
                        trControl = trainControl(method = "cv", number = 10),
                        tuneGrid = expand.grid(cp = seq(0.0, 0.01, 0.0001)),
                        control = rpart.control(minbucket = 1)
                        )
plot(new_tree)
```

```{r}
rpart.plot(new_tree$finalModel)
```

## Interpret Error

When looking at our error, we see that our Testing Data has the highest RMSE.

Our Training and Cross-Validation data seem to have very similar RMSE, but our Training has the smallest amount of RMSE present.

When looking at this, it makes sense for our Testing to have the highest RMSE present and for our Training to the smallest. The Testing data being used with our developed model was not trained to fit our model like our Training data. A similar RMSE between Training and Cross-Validation means that the model is fitting well to the Training data.

Our Testing data is a measure of how well the fitted model will predict, not how well it fits data that was used to train the model.

```{r}
train_error = postResample(predict(new_tree, train), train$charges)[["RMSE"]]

cv_error = min(new_tree$results$RMSE)

test_error = postResample(predict(new_tree, test), test$charges)[["RMSE"]]

data.frame(
  "Error Source" = c("Training", "Cross-Validation", "Testing"),
  "RMSE" = c(train_error, cv_error, test_error)
)
```

## Conclusion

In conclusion, our project sought to develop a predictive model for estimating health insurance charges based on factors such as demographics and lifestyle. We used the CRISP-DM for the machine learning process as a way to guide our project. Our findings lead us to reveal that the factors that influence health insurance charges the most are `age`, `BMI`, and `smoking status`. However, we found out that the model's performance on testing data had challenges we needed to look into. We found out valuable insight into the decision making process involved in estimating health care charges.
